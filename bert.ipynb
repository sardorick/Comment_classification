{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\r\\nWhy the edits made under my use...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\r\\nMore\\r\\nI can't make any real suggestions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  Explanation\\r\\nWhy the edits made under my use...      0             0   \n",
       "1  D'aww! He matches this background colour I'm s...      0             0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0             0   \n",
       "3  \"\\r\\nMore\\r\\nI can't make any real suggestions...      0             0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \n",
       "0        0       0       0              0  \n",
       "1        0       0       0              0  \n",
       "2        0       0       0              0  \n",
       "3        0       0       0              0  \n",
       "4        0       0       0              0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/toxic_comments.csv').drop(columns='id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what's the approximate word count?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = df.comment_text.apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='comment_text', ylabel='Count'>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(x = word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    159571.000000\n",
       "mean         67.273527\n",
       "std          99.230702\n",
       "min           1.000000\n",
       "25%          17.000000\n",
       "50%          36.000000\n",
       "75%          75.000000\n",
       "max        1411.000000\n",
       "Name: comment_text, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.describe()\n",
    "# We'll take the median (36) as our max sequence length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### subsampling, train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df.sample(500).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 36\n",
    "batch_size = 32\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1000, 1045, 4033, 1005, 1056, 11498, 8458, 23797, 2094, 2017, 2012, 2035, 1010, 5639, 1012, 2017, 10865, 2008, 21393, 3522, 4216, 2000, 2216, 1000, 1000, 2092, 2058, 1017, 2086, 2214, 1000, 1000, 2003, 1000, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# token ids needed to retrieve embeddings\n",
    "inputs = tokenizer.encode_plus(\n",
    "            sample.comment_text[0],\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxCOmmentDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len):\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "        self.df = df\n",
    "        self.comments = df.comment_text\n",
    "        self.targets = df.drop(columns='comment_text').values.tolist()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        comment = self.comments[index]\n",
    "        targets = self.targets[index]\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            comment,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"] \n",
    "\n",
    "        return {\n",
    "                'ids': torch.tensor(ids, dtype=torch.long),\n",
    "                'mask': torch.tensor(mask, dtype=torch.long),\n",
    "                'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "                'targets': torch.tensor(targets, dtype=torch.float)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400, 7), (100, 7))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(sample, test_size=0.2)\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "test_data.reset_index(drop=True, inplace=True)\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = ToxCOmmentDataset(train_data, tokenizer, max_len)\n",
    "test_set = ToxCOmmentDataset(test_data, tokenizer, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ids': tensor([  101,  1000,  2089,  2268,  3531,  2079,  2025,  3158,  9305,  4697,\n",
       "          5530,  1010,  2004,  2017,  2106,  2007,  2023, 10086,  2000, 11268,\n",
       "          7088,  3723,  1012,  2065,  2017,  3613,  2000,  2079,  2061,  1010,\n",
       "          2017,  2097,  2022,  8534,  2013,   102]),\n",
       " 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'targets': tensor([0., 0., 0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_set))\n",
    "train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_set, batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 36]), torch.Size([32, 6]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_loader))\n",
    "iter(train_loader).next()['ids'].shape, iter(train_loader).next()['targets'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (emb): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, bert_model):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.emb = bert_model # creating the embeddings (with emb dim == 768)\n",
    "        self.fc = nn.Linear(768, 6)\n",
    "    \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        output = self.emb(ids, attention_mask = mask, token_type_ids = token_type_ids)\n",
    "        output = output.pooler_output\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "model = Classifier(bert_model)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_y = iter(train_loader).next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = bert_model(x_y['ids'], attention_mask = x_y['mask'], token_type_ids = x_y[\"token_type_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output'])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 6]), torch.Size([32, 6]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test model\n",
    "y_true = x_y['targets']\n",
    "logits = model(x_y['ids'], x_y['mask'], x_y[\"token_type_ids\"])\n",
    "y_true.shape, logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_value = y_true.int().numpy()\n",
    "true_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 0, 0, 1],\n",
       "       [0, 1, 1, 0, 1, 0],\n",
       "       [1, 1, 1, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 1, 0],\n",
       "       [1, 1, 1, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 0, 0, 0],\n",
       "       [1, 1, 1, 0, 0, 1],\n",
       "       [1, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 1, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 0, 1, 0],\n",
       "       [1, 1, 1, 0, 0, 1],\n",
       "       [0, 1, 1, 0, 0, 0],\n",
       "       [0, 1, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = ((torch.sigmoid(logits) >= 0.5).int()).numpy()\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09375"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(true_value, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8125 , 0.96875, 0.     , 0.9375 , 0.     , 0.96875])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_true.int().numpy() == ((torch.sigmoid(logits) >= 0.5).int()).numpy())/32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(params=model.parameters(), lr = learning_rate)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "n_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Epoch 1 #############\n",
      "TrainLoss: 0.3736\n",
      "TestLoss: 0.1750\n",
      "TestAccu: 89.58%\n",
      "Time: 144.3351\n",
      "############# Epoch 2 #############\n",
      "TrainLoss: 0.1576\n",
      "TestLoss: 0.1754\n",
      "TestAccu: 89.58%\n",
      "Time: 141.7153\n",
      "############# Epoch 3 #############\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\strive_school\\work\\CHALLENGE\\Chap3\\toxic_comment_classification\\bert.ipynb Cell 32'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/strive_school/work/CHALLENGE/Chap3/toxic_comment_classification/bert.ipynb#ch0000027?line=26'>27</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/strive_school/work/CHALLENGE/Chap3/toxic_comment_classification/bert.ipynb#ch0000027?line=28'>29</a>\u001b[0m \u001b[39m# backward\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/strive_school/work/CHALLENGE/Chap3/toxic_comment_classification/bert.ipynb#ch0000027?line=29'>30</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/strive_school/work/CHALLENGE/Chap3/toxic_comment_classification/bert.ipynb#ch0000027?line=31'>32</a>\u001b[0m \u001b[39m# weights update\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/strive_school/work/CHALLENGE/Chap3/toxic_comment_classification/bert.ipynb#ch0000027?line=32'>33</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\strive\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    355\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    356\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    357\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    361\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    362\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 363\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\strive\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "benchmark_acc = 0.70\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "test_acc = []\n",
    "for epoch in range(n_epochs):\n",
    "    running_train_loss = 0\n",
    "    running_test_loss = 0\n",
    "    running_test_acc = 0\n",
    "    \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    print('############# Epoch {} #############'.format(epoch + 1))\n",
    "    start = time.time()\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # pack out needed data for the model\n",
    "        ids = data['ids'].to(device)\n",
    "        mask = data['mask'].to(device)\n",
    "        token_type_ids = data['token_type_ids'].to(device)\n",
    "        targets = data['targets'].to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "        # Cost\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # backward\n",
    "        loss.backward()\n",
    "\n",
    "        # weights update\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        running_train_loss += loss.item()\n",
    "    train_losses.append(running_train_loss / len(train_loader))\n",
    "    \n",
    "    print(f'TrainLoss: {train_losses[-1] :.4f}')\n",
    "    \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    " \n",
    "    model.eval()\n",
    "   \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(test_loader):\n",
    "            ids = data['ids'].to(device)\n",
    "            mask = data['mask'].to(device)\n",
    "            token_type_ids = data['token_type_ids'].to(device)\n",
    "            targets = data['targets'].to(device)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            running_test_loss += loss.item()\n",
    "\n",
    "            # accuracy\n",
    "            targets = targets.cpu().int().numpy()\n",
    "            probs = torch.sigmoid(outputs).cpu().detach()\n",
    "            preds = (probs >= 0.5).int().numpy()\n",
    "\n",
    "            running_test_acc += accuracy_score(targets, preds)\n",
    "\n",
    "        test_acc.append(running_test_acc / len(test_loader))\n",
    "        test_losses.append(running_test_loss / len(test_loader))\n",
    "        print(f'TestLoss: {test_losses[-1] :.4f}')\n",
    "        print(f'TestAccu: {test_acc[-1] *100 :.2f}%')\n",
    "        print(f'Time: {time.time() - start :.4f}')\n",
    "\n",
    "\n",
    "        # save best model\n",
    "        if test_acc[-1] > benchmark_acc:\n",
    "            # save model to cpu\n",
    "            torch.save(model.to('cpu').state_dict(), './model.pth')\n",
    "            \n",
    "\n",
    "            # update benckmark\n",
    "            benchmark_acc = test_acc[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model.pth')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(comment, tokenizer):\n",
    "    inputs = tokenizer.encode_plus(\n",
    "            comment,\n",
    "            add_special_tokens=True,\n",
    "            max_length=36,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "    ids = inputs['input_ids']\n",
    "    mask = inputs['attention_mask']\n",
    "    token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "    return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long).unsqueeze(0),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long).unsqueeze(0),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long).unsqueeze(0)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_labels = df.drop(columns='comment_text').columns.to_list()\n",
    "target_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0413, 0.0100, 0.0416, 0.0016, 0.0324, 0.0131]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text = \"I've never read such a boring book!!!\"\n",
    "\n",
    "\n",
    "def predict(model, comment, tokenizer):\n",
    "    \n",
    "    # preprocessing\n",
    "    data = preprocessing(comment, tokenizer)\n",
    "    ids = data['ids']\n",
    "    mask = data['mask']\n",
    "    token_type_ids = data['token_type_ids']\n",
    "\n",
    "    # prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(ids, mask, token_type_ids)\n",
    "        \n",
    "\n",
    "    return torch.sigmoid(logits)\n",
    "\n",
    "\n",
    "predict(model, example_text, tokenizer)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('strive')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57b4146e8602cb0ff91512065bdb02700ac9f9d6ea9aa046f2e5f7c3a69675f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
